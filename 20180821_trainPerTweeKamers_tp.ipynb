{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wv\n",
    "import scipy.signal as sig\n",
    "import wave\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from util import util\n",
    "from util import WavFileParts\n",
    "from util.logUtil import LOG, LOG_HEADER\n",
    "from util.confusionMatrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### globale settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['music', 'voice', 'environment']\n",
    "\n",
    "macDir = '/Volumes/SAA_DATA/datasets/'\n",
    "winDir = 'E:/SAA_DATA/'\n",
    "osDir = macDir\n",
    "recordingDir = osDir + '/localizationRecordings'\n",
    "\n",
    "if osDir == winDir:\n",
    "    storageFolder = 'E:/SAA_DATA/storedData/'\n",
    "else:\n",
    "    storageFolder = '/Users/etto/Desktop/storedData/'\n",
    "\n",
    "baseSrcDir = osDir + 'localizationFiles/20171025AllExtractionsMic4'\n",
    "orgWavDirs1 = ['G428_0.0_1.4',\n",
    "              'G527_0.5_1.4',\n",
    "              'Studio_2.0_4.2'\n",
    "              ]\n",
    "\n",
    "orgWavDirs2 = ['G428_2.1_2.4',\n",
    "              'G527_1.2_5.8',\n",
    "              'Studio_3.0_2.0'\n",
    "              ]\n",
    "\n",
    "orgsG428 = ['G428_0.0_1.4','G428_2.1_2.4']\n",
    "orgsG527 = ['G527_0.5_1.4','G527_1.2_5.8']\n",
    "orgsStudio = ['Studio_2.0_4.2','Studio_3.0_2.0']\n",
    "\n",
    "NFFT = 1024\n",
    "\n",
    "chunksBaseDir = 'chunks'\n",
    "rooms = ['Studio', 'G428', 'G527']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSoundChunksDynamic(moduleString):\n",
    "    chunks = importlib.import_module(moduleString).soundChunks\n",
    "    wfPts = []\n",
    "    for jsonString in chunks:\n",
    "        wfPts.append(WavFileParts.WavFilePartFromJson(jsonString))\n",
    "    return wfPts\n",
    "\n",
    "def timeFunction(func):\n",
    "    \"\"\"\n",
    "    Aanroep: bijv. fpc = timeFunction(lambda: getFilesPerCategory(srcDir))\n",
    "    \"\"\"\n",
    "    startTime = datetime.now()\n",
    "    print('Start: ' + startTime.strftime('%H:%M:%S') + '\\n=================')\n",
    "\n",
    "    res = func()\n",
    "    \n",
    "    endTime = datetime.now()\n",
    "    print('\\n=================\\nEnd: ' + endTime.strftime('%H:%M:%S'))\n",
    "    print('Time taken: '),\n",
    "    print(endTime - startTime)\n",
    "    print()\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def storeTestData(allSpectros, allClasses, storageName, keyName):\n",
    "    filename = storageFolder + storageName + '.hd5'\n",
    "    df = pd.DataFrame(allSpectros)\n",
    "    df.to_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "\n",
    "    df = pd.DataFrame(allClasses)\n",
    "    df.to_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "\n",
    "def retrieveTestData(storageName, keyName):\n",
    "    filename = storageFolder + storageName + '.hd5'\n",
    "    specDf = pd.read_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "    classesDf = pd.read_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "    return specDf.values, classesDf.values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie alle files (volledig pad) uit de srcDir\n",
    "# srcDir is een van de orgWavDirs, bijvoorbeeld\n",
    "#    localizationFiles/20171025AllExtractionsMic4/G428_0.0_1.4\n",
    "def getFilesPerCategory(srcDir):\n",
    "    filesPerCategory = {}\n",
    "    for catDirLong in glob.glob(srcDir + '/*'):\n",
    "        catDir = catDirLong.replace('\\\\', '/')\n",
    "        catDir = catDir.replace(srcDir + '/', '')\n",
    "\n",
    "        filesPerCategory[catDir] = []\n",
    "        for filename in glob.glob(catDirLong + '/*'):\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            filesPerCategory[catDir].append(filename)\n",
    "    return filesPerCategory\n",
    "\n",
    "def getFilesPerCatFromMultipleDirs(srcDirs, srcDirsBase=''):\n",
    "    filesPerCat = {}\n",
    "    for dirName in srcDirs:\n",
    "        srcDir = srcDirsBase + '/' + dirName\n",
    "        fpcNw = getFilesPerCategory(srcDir)\n",
    "        if not filesPerCat:\n",
    "            filesPerCat = fpcNw\n",
    "        else:\n",
    "            for key in filesPerCat:\n",
    "                filesPerCat[key] += fpcNw[key]\n",
    "    return filesPerCat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie de spectrogrammen\n",
    "def getSpectrosFromFilesPerCategory(filesPerCategory):\n",
    "    spectros = {}\n",
    "    for clz in classes:\n",
    "        spectros[clz] = []\n",
    "        for filename in filesPerCategory[clz]:\n",
    "            fs, signal = wv.read(filename)\n",
    "            freq_array, segment_times, spectrogram = sig.spectrogram(x=signal, fs=fs, nfft=NFFT, noverlap=0)\n",
    "            spectros[clz].append(spectrogram.T)\n",
    "    return spectros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassLengths(spectrosPerCat):\n",
    "    clzLengths = {}\n",
    "    for clz in classes:\n",
    "        clzLengths[clz] = sum([np.shape(lst)[0] for lst in spectrosPerCat[clz]])\n",
    "    return clzLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verwacht invoer van getSpectrosFromFilesPerCategory\n",
    "# levert traindata op (X_train en Y_train)\n",
    "def createTrainDataFromSpectros(spectrosPerCat, clzLengths):\n",
    "    X_train = np.concatenate(spectrosPerCat[classes[0]], axis=0)\n",
    "    for i in range(1, len(classes)):\n",
    "        nwSpectros = np.concatenate(spectrosPerCat[classes[i]], axis=0)\n",
    "        X_train = np.concatenate((X_train,nwSpectros), axis=0)\n",
    "    \n",
    "    # one-hot encoding voor Y_train\n",
    "    nrFiles = clzLengths[classes[0]]\n",
    "    Y_train = np.array((np.ones(nrFiles),np.zeros(nrFiles), np.zeros(nrFiles))).T\n",
    "\n",
    "    nrFiles = clzLengths[classes[1]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.ones(nrFiles), np.zeros(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "\n",
    "    nrFiles = clzLengths[classes[2]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.zeros(nrFiles), np.ones(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "    \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layersizes):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layersizes[0], input_dim=513, activation='relu'))\n",
    "    for lsize in layersizes[1:]:\n",
    "        model.add(Dense(lsize, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs):\n",
    "    modelFilename = modelFilePath + baseModelFilename\n",
    "    for lsize in layers:\n",
    "        modelFilename = '{}_{}'.format(modelFilename, lsize)\n",
    "    modelFilename += 'ep{}'.format(nrEpochs)\n",
    "    modelFilename += '.hd5'\n",
    "    return modelFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelName(baseModelFilename, layers, nrEpochs):\n",
    "    modelFilename = baseModelFilename\n",
    "    for lsize in layers:\n",
    "        modelFilename = '{}_{}'.format(modelFilename, lsize)\n",
    "    modelFilename += 'ep{}'.format(nrEpochs)\n",
    "    return modelFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = create_model(layers)\n",
    "    history = timeFunction(lambda: soundModel.fit(X_train,Y_train, epochs=nrEpochs, shuffle=True, verbose=1))\n",
    "    soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = load_model(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "\n",
    "    # predicted classes\n",
    "    predictions = soundModel.predict(X_test)\n",
    "    predClasses = predictions.argmax(axis=1)\n",
    "\n",
    "    matrix = ConfusionMatrix(classes)\n",
    "    for vals in zip(realClasses, predClasses):\n",
    "        matrix.add(int(vals[0]), int(vals[1]), 1)\n",
    "    LOG(matrix.toString(),True)\n",
    "    LOG('', True)\n",
    "    LOG(matrix.toF1String(), True)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_per_epoch(X_train, Y_train, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = create_model(layers)\n",
    "    for epNr in range(1, nrEpochs+1):\n",
    "        LOG('\\n*****************\\n* Epoch nr {}\\n*****************\\n'.format(epNr), True)\n",
    "        soundModel.fit(X_train,Y_train, epochs=1, shuffle=True, verbose=1)\n",
    "        soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, epNr))\n",
    "        evaluate_model(X_train, realClasses, layers, epNr, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndStoreTestData(wavFileParts, baseDir, fileDate, micNr, storeFilename, keyName):\n",
    "    allSpectros = np.array([])\n",
    "    allClasses = np.array([])\n",
    "\n",
    "    for wfPt in wavFileParts: #type: WavFilePart\n",
    "        if not 'Gunshot' in wfPt.getSoundType():\n",
    "            filename = baseDir + '/{:d}_{:d}_mono{:d}.wav'.format(fileDate, wfPt.fileNr, micNr)\n",
    "            fs, signal = wv.read(filename)\n",
    "\n",
    "            classNr = classes.index(wfPt.getSoundType().lower())\n",
    "            for soundChunk in wfPt.getSoundChunks(micNr):\n",
    "                startFrame = int(soundChunk[0] * fs)\n",
    "                endFrame = int(soundChunk[1] * fs)\n",
    "\n",
    "                sigChunk = signal[startFrame: endFrame]\n",
    "                freq_array, segment_times, spectrogram = sig.spectrogram(x=sigChunk, fs=fs, nfft=NFFT, noverlap=0)\n",
    "                if len(allSpectros) == 0:\n",
    "                    allSpectros = spectrogram.T\n",
    "                else:\n",
    "                    allSpectros = np.append(allSpectros, spectrogram.T, axis=0)\n",
    "                allClasses = np.append(allClasses, classNr * np.ones(len(segment_times)))\n",
    "                \n",
    "    storeTestData(allSpectros, allClasses, storeFilename, keyName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataFromFolders(orgWavDirs):\n",
    "    fpc = getFilesPerCatFromMultipleDirs(orgWavDirs, baseSrcDir)\n",
    "    spcs = getSpectrosFromFilesPerCategory(fpc)\n",
    "    clzLengths = getClassLengths(spcs)\n",
    "    X_train, Y_train = createTrainDataFromSpectros(spcs, clzLengths)\n",
    "    # real train classes\n",
    "    realTrainClasses = np.concatenate((np.zeros(clzLengths[classes[0]]), \n",
    "                                  np.ones(clzLengths[classes[1]]), \n",
    "                                  2*np.ones(clzLengths[classes[2]])))\n",
    "    return X_train, Y_train, realTrainClasses\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainen van model obv: G428 en G527"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModelFilename = '20180821_orgG428_G527'\n",
    "modelFilePath = storageFolder\n",
    "logPrefix = 'Orgs G428 en G527'\n",
    "orgWavDirs = orgsG428 + orgsG527\n",
    "layersList = [[100, 20], [400, 250, 100, 20], [400, 300, 200, 100, 50, 20, 10], \n",
    "              [450, 400, 350, 300, 250, 200, 150, 100, 50, 21]]\n",
    "nrEpochs = 3\n",
    "nrsEpochs = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train voor alle lagen\n",
    "X_train, Y_train, realTrainClasses = getTrainDataFromFolders(orgWavDirs)\n",
    "for layers in layersList:\n",
    "    LOG_HEADER(logPrefix + ', lagen: {}'.format(str(layers)), True)\n",
    "    train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test alle modellen\n",
    "\n",
    "# model parameters\n",
    "modelFilePath = storageFolder\n",
    "layerss = layersList\n",
    "\n",
    "# test data\n",
    "micNr = 4\n",
    "testFileNames = ['testData_G428', 'testData_G527', 'testData_Studio']\n",
    "keyname = 'mic{}'.format(micNr)\n",
    "\n",
    "for testFileName in testFileNames:\n",
    "    for layers in layerss:\n",
    "        for nrEpochs in nrsEpochs:\n",
    "            testSpecs, testClasses = retrieveTestData(testFileName, keyname)\n",
    "\n",
    "            LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                       + '\\n# ' + keyname\n",
    "                       + '\\n# ' + testFileName,\n",
    "                       True)\n",
    "            matrix = evaluate_model(testSpecs, testClasses, layers, nrEpochs, modelFilePath, baseModelFilename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainen van model obv: G527 en Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModelFilename = '20180821_orgG527_Studio'\n",
    "logPrefix = 'Orgs G527 en Studio'\n",
    "orgWavDirs = orgsG527 + orgsStudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train voor alle lagen\n",
    "X_train, Y_train, realTrainClasses = getTrainDataFromFolders(orgWavDirs)\n",
    "for layers in layersList:\n",
    "    LOG_HEADER(logPrefix + ', lagen: {}'.format(str(layers)), True)\n",
    "    train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test alle modellen\n",
    "\n",
    "# model parameters\n",
    "modelFilePath = storageFolder\n",
    "layerss = layersList\n",
    "\n",
    "# test data\n",
    "micNr = 4\n",
    "testFileNames = ['testData_G428', 'testData_G527', 'testData_Studio']\n",
    "keyname = 'mic{}'.format(micNr)\n",
    "\n",
    "for testFileName in testFileNames:\n",
    "    for layers in layerss:\n",
    "        for nrEpochs in nrsEpochs:\n",
    "            testSpecs, testClasses = retrieveTestData(testFileName, keyname)\n",
    "\n",
    "            LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                       + '\\n# ' + keyname\n",
    "                       + '\\n# ' + testFileName,\n",
    "                       True)\n",
    "            matrix = evaluate_model(testSpecs, testClasses, layers, nrEpochs, modelFilePath, baseModelFilename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainen van model obv: Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseModelFilename = '20180817_orgStudio_G428'\n",
    "modelFilePath = storageFolder\n",
    "logPrefix = 'Orgs Studio en G428'\n",
    "orgWavDirs = orgsStudio + orgsG428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train voor alle lagen\n",
    "X_train, Y_train, realTrainClasses = getTrainDataFromFolders(orgWavDirs)\n",
    "for layers in layersList:\n",
    "    LOG_HEADER(logPrefix + ', lagen: {}'.format(str(layers)), True)\n",
    "    train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Test alle modellen\n",
    "\n",
    "# model parameters\n",
    "modelFilePath = storageFolder\n",
    "layerss = layersList\n",
    "\n",
    "# test data\n",
    "micNr = 4\n",
    "testFileNames = ['testData_G428', 'testData_G527', 'testData_Studio']\n",
    "keyname = 'mic{}'.format(micNr)\n",
    "\n",
    "for testFileName in testFileNames:\n",
    "    for layers in layerss:\n",
    "        for nrEpochs in nrsEpochs:\n",
    "            testSpecs, testClasses = retrieveTestData(testFileName, keyname)\n",
    "\n",
    "            LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                       + '\\n# ' + keyname\n",
    "                       + '\\n# ' + testFileName,\n",
    "                       True)\n",
    "            matrix = evaluate_model(testSpecs, testClasses, layers, nrEpochs, modelFilePath, baseModelFilename)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "251px",
    "left": "448.415px",
    "right": "20px",
    "top": "98.9773px",
    "width": "579px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
