{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wv\n",
    "import scipy.signal as sig\n",
    "import wave\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from util import util\n",
    "from util import WavFileParts\n",
    "from util.logUtil import LOG, LOG_HEADER\n",
    "from util.confusionMatrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### globale settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['music', 'voice', 'environment']\n",
    "\n",
    "macDir = '/Volumes/SAA_DATA/datasets/'\n",
    "winDir = 'E:/SAA_DATA/'\n",
    "osDir = winDir\n",
    "\n",
    "baseTargetDir = '/Users/etto/Desktop/pData'\n",
    "baseTargetDir = 'E:/SAA_DATA/targetDir'\n",
    "\n",
    "baseSrcDir = osDir + 'localizationFiles/20171025AllExtractionsMic4'\n",
    "orgWavDirs1 = ['G428_0.0_1.4',\n",
    "              'G527_0.5_1.4',\n",
    "              'Studio_2.0_4.2'\n",
    "              ]\n",
    "\n",
    "orgWavDirs2 = ['G428_2.1_2.4',\n",
    "              'G527_1.2_5.8',\n",
    "              'Studio_3.0_2.0'\n",
    "              ]\n",
    "\n",
    "NFFT = 1024\n",
    "\n",
    "storageFolder = '../storedData/'\n",
    "chunksBaseDir = 'chunks'\n",
    "rooms = ['Studio', 'G428', 'G527']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSoundChunksDynamic(moduleString):\n",
    "    chunks = importlib.import_module(moduleString).soundChunks\n",
    "    wfPts = []\n",
    "    for jsonString in chunks:\n",
    "        wfPts.append(WavFileParts.WavFilePartFromJson(jsonString))\n",
    "    return wfPts\n",
    "\n",
    "def timeFunction(func):\n",
    "    \"\"\"\n",
    "    Aanroep: bijv. fpc = timeFunction(lambda: getFilesPerCategory(srcDir))\n",
    "    \"\"\"\n",
    "    startTime = datetime.now()\n",
    "    print('Start: ' + startTime.strftime('%H:%M:%S') + '\\n=================')\n",
    "\n",
    "    res = func()\n",
    "    \n",
    "    endTime = datetime.now()\n",
    "    print('\\n=================\\nEnd: ' + endTime.strftime('%H:%M:%S'))\n",
    "    print('Time taken: '),\n",
    "    print(endTime - startTime)\n",
    "    print()\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def storeTestData(allSpectros, allClasses, storageName, keyName):\n",
    "    filename = storageFolder + storageName + '.hd5'\n",
    "    df = pd.DataFrame(allSpectros)\n",
    "    df.to_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "\n",
    "    df = pd.DataFrame(allClasses)\n",
    "    df.to_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "\n",
    "def retrieveTestData(storageName, keyName):\n",
    "    filename = storageFolder + storageName + '.hd5'\n",
    "    specDf = pd.read_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "    classesDf = pd.read_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "    return specDf, classesDf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie alle files (volledig pad) uit de srcDir\n",
    "# srcDir is een van de orgWavDirs, bijvoorbeeld\n",
    "#    localizationFiles/20171025AllExtractionsMic4/G428_0.0_1.4\n",
    "def getFilesPerCategory(srcDir):\n",
    "    filesPerCategory = {}\n",
    "    for catDirLong in glob.glob(srcDir + '/*'):\n",
    "        catDir = catDirLong.replace('\\\\', '/')\n",
    "        catDir = catDir.replace(srcDir + '/', '')\n",
    "\n",
    "        filesPerCategory[catDir] = []\n",
    "        for filename in glob.glob(catDirLong + '/*'):\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            filesPerCategory[catDir].append(filename)\n",
    "    return filesPerCategory\n",
    "\n",
    "def getFilesPerCatFromMultipleDirs(srcDirs, srcDirsBase=''):\n",
    "    filesPerCat = {}\n",
    "    for dirName in srcDirs:\n",
    "        srcDir = srcDirsBase + '/' + dirName\n",
    "        fpcNw = getFilesPerCategory(srcDir)\n",
    "        if not filesPerCat:\n",
    "            filesPerCat = fpcNw\n",
    "        else:\n",
    "            for key in filesPerCat:\n",
    "                filesPerCat[key] += fpcNw[key]\n",
    "    return filesPerCat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie de spectrogrammen\n",
    "def getSpectrosFromFilesPerCategory(filesPerCategory):\n",
    "    spectros = {}\n",
    "    for clz in classes:\n",
    "        spectros[clz] = []\n",
    "        for filename in filesPerCategory[clz]:\n",
    "            fs, signal = wv.read(filename)\n",
    "            freq_array, segment_times, spectrogram = sig.spectrogram(x=signal, fs=fs, nfft=NFFT, noverlap=0)\n",
    "            spectros[clz].append(spectrogram.T)\n",
    "    return spectros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassLengths(spectrosPerCat):\n",
    "    clzLengths = {}\n",
    "    for clz in classes:\n",
    "        clzLengths[clz] = sum([np.shape(lst)[0] for lst in spectrosPerCat[clz]])\n",
    "    return clzLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verwacht invoer van getSpectrosFromFilesPerCategory\n",
    "# levert traindata op (X_train en Y_train)\n",
    "def createTrainDataFromSpectros(spectrosPerCat, clzLengths):\n",
    "    X_train = np.concatenate(spectrosPerCat[classes[0]], axis=0)\n",
    "    for i in range(1, len(classes)):\n",
    "        nwSpectros = np.concatenate(spectrosPerCat[classes[i]], axis=0)\n",
    "        X_train = np.concatenate((X_train,nwSpectros), axis=0)\n",
    "    \n",
    "    # one-hot encoding voor Y_train\n",
    "    nrFiles = clzLengths[classes[0]]\n",
    "    Y_train = np.array((np.ones(nrFiles),np.zeros(nrFiles), np.zeros(nrFiles))).T\n",
    "\n",
    "    nrFiles = clzLengths[classes[1]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.ones(nrFiles), np.zeros(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "\n",
    "    nrFiles = clzLengths[classes[2]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.zeros(nrFiles), np.ones(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "    \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layersizes):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layersizes[0], input_dim=513, activation='relu'))\n",
    "    for lsize in layersizes[1:]:\n",
    "        model.add(Dense(lsize, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs):\n",
    "    modelFilename = modelFilePath + baseModelFilename\n",
    "    for lsize in layers:\n",
    "        modelFilename = '{}_{}'.format(modelFilename, lsize)\n",
    "    modelFilename += 'ep{}'.format(nrEpochs)\n",
    "    modelFilename += '.hd5'\n",
    "    return modelFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = create_model(layers)\n",
    "    history = timeFunction(lambda: soundModel.fit(X_train,Y_train, epochs=nrEpochs, shuffle=True, verbose=1))\n",
    "    soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = load_model(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "\n",
    "    # predicted classes\n",
    "    predictions = soundModel.predict(X_test)\n",
    "    predClasses = predictions.argmax(axis=1)\n",
    "\n",
    "    matrix = ConfusionMatrix(classes)\n",
    "    for vals in zip(realClasses, predClasses):\n",
    "        matrix.add(int(vals[0]), int(vals[1]), 1)\n",
    "    LOG(matrix.toString(),True)\n",
    "    LOG('', True)\n",
    "    LOG(matrix.toF1String(), True)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_per_epoch(X_train, Y_train, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = create_model(layers)\n",
    "    for epNr in range(1, nrEpochs+1):\n",
    "        LOG('\\n*****************\\n* Epoch nr {}\\n*****************\\n'.format(epNr), True)\n",
    "        soundModel.fit(X_train,Y_train, epochs=1, shuffle=True, verbose=1)\n",
    "        soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, epNr))\n",
    "        evaluate_model(X_train, realClasses, layers, epNr, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainen van model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bepaal train data\n",
    "srcDir = baseSrcDir + '/' + orgWavDirs1[0]\n",
    "# fpc = getFilesPerCategory(srcDir)\n",
    "fpc = getFilesPerCatFromMultipleDirs(orgWavDirs1 + orgWavDirs2, baseSrcDir)\n",
    "spcs = getSpectrosFromFilesPerCategory(fpc)\n",
    "clzLengths = getClassLengths(spcs)\n",
    "X_train, Y_train = createTrainDataFromSpectros(spcs, clzLengths)\n",
    "# real train classes\n",
    "realTrainClasses = np.concatenate((np.zeros(clzLengths[classes[0]]), \n",
    "                              np.ones(clzLengths[classes[1]]), \n",
    "                              2*np.ones(clzLengths[classes[2]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "#\n",
      "# Alle orgs, lagen: [100, 20]\n",
      "#\n",
      "####################################\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 1\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 113s 102us/step - loss: 0.1799 - acc: 0.9338\n",
      "                   m       v       e |  sens   acc\n",
      "music         351223   14553     760 |  0.96  0.97\n",
      "voice          18017  339738    8968 |  0.93  0.96\n",
      "environment     1291    8015  365740 |  0.98  0.98\n",
      "--------------------------------------\n",
      "prec            0.95    0.94    0.97\n",
      "\n",
      "F1 overall: 0.95\n",
      "F1 music: 0.95\n",
      "F1 voice: 0.93\n",
      "F1 environment: 0.97\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 2\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 111s 100us/step - loss: 0.1163 - acc: 0.9569\n",
      "                   m       v       e |  sens   acc\n",
      "music         350210   15815     511 |  0.96  0.98\n",
      "voice          10001  348236    8486 |  0.95  0.96\n",
      "environment      898    6086  368062 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.97    0.94    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 3\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 112s 101us/step - loss: 0.1033 - acc: 0.9618\n",
      "                   m       v       e |  sens   acc\n",
      "music         351279   14614     643 |  0.96  0.98\n",
      "voice           8752  352298    5673 |  0.96  0.97\n",
      "environment      575    8286  366185 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.97    0.94    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 4\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 114s 102us/step - loss: 0.0970 - acc: 0.9640\n",
      "                   m       v       e |  sens   acc\n",
      "music         354265   11899     372 |  0.97  0.98\n",
      "voice          10595  351056    5072 |  0.96  0.97\n",
      "environment      739    8444  365863 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.97    0.95    0.99\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 5\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 113s 102us/step - loss: 0.0929 - acc: 0.9658\n",
      "                   m       v       e |  sens   acc\n",
      "music         354033   11866     637 |  0.97  0.98\n",
      "voice          10390  349989    6344 |  0.95  0.97\n",
      "environment      473    6143  368430 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.97    0.95    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseModelFilename = '20180720_allOrgs'\n",
    "modelFilePath = storageFolder\n",
    "layers = [100, 20]\n",
    "\n",
    "LOG_HEADER('Alle orgs, lagen: [100, 20]', True)\n",
    "\n",
    "nrEpochs = 5\n",
    "train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "#\n",
      "# Alle orgs, lagen: [400, 250, 100, 20]\n",
      "#\n",
      "####################################\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 1\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 171s 154us/step - loss: 0.1454 - acc: 0.9462\n",
      "                   m       v       e |  sens   acc\n",
      "music         349038   16865     633 |  0.95  0.98\n",
      "voice           8966  351792    5965 |  0.96  0.96\n",
      "environment      852    9744  364450 |  0.97  0.98\n",
      "--------------------------------------\n",
      "prec            0.97    0.93    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.94\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 2\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 174s 157us/step - loss: 0.1049 - acc: 0.9611\n",
      "                   m       v       e |  sens   acc\n",
      "music         349291   16613     632 |  0.95  0.98\n",
      "voice           7034  352748    6941 |  0.96  0.97\n",
      "environment      654    7602  366790 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.94    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 3\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 176s 158us/step - loss: 0.0953 - acc: 0.9648\n",
      "                   m       v       e |  sens   acc\n",
      "music         351341   14350     845 |  0.96  0.98\n",
      "voice           6838  355436    4449 |  0.97  0.97\n",
      "environment      344    8347  366355 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.94    0.99\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 4\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 173s 156us/step - loss: 0.0893 - acc: 0.9670\n",
      "                   m       v       e |  sens   acc\n",
      "music         352731   13127     678 |  0.96  0.98\n",
      "voice           8053  351714    6956 |  0.96  0.97\n",
      "environment      501    4710  369835 |  0.99  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.95    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.96\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 5\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 177s 160us/step - loss: 0.0857 - acc: 0.9687\n",
      "                   m       v       e |  sens   acc\n",
      "music         350893   15268     375 |  0.96  0.98\n",
      "voice           5055  354981    6687 |  0.97  0.97\n",
      "environment      421    4605  370020 |  0.99  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.95    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.96\n",
      "F1 environment: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseModelFilename = '20180720_allOrgs'\n",
    "modelFilePath = storageFolder\n",
    "layers = [400, 250, 100, 20]\n",
    "\n",
    "LOG_HEADER('Alle orgs, lagen: [400, 250, 100, 20]', True)\n",
    "\n",
    "nrEpochs = 5\n",
    "train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "#\n",
      "# Alle orgs, lagen: [400, 300, 200, 100, 50, 20, 10]\n",
      "#\n",
      "####################################\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 1\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 256s 231us/step - loss: 0.1500 - acc: 0.9447\n",
      "                   m       v       e |  sens   acc\n",
      "music         351060   14902     574 |  0.96  0.97\n",
      "voice          12137  345444    9142 |  0.94  0.96\n",
      "environment     1391    7256  366399 |  0.98  0.98\n",
      "--------------------------------------\n",
      "prec            0.96    0.94    0.97\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.94\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 2\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 256s 231us/step - loss: 0.1077 - acc: 0.9603\n",
      "                   m       v       e |  sens   acc\n",
      "music         354786   11054     696 |  0.97  0.98\n",
      "voice          13582  348212    4929 |  0.95  0.96\n",
      "environment      564    9527  364955 |  0.97  0.99\n",
      "--------------------------------------\n",
      "prec            0.96    0.94    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 3\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 255s 230us/step - loss: 0.0979 - acc: 0.9643\n",
      "                   m       v       e |  sens   acc\n",
      "music         352377   13649     510 |  0.96  0.98\n",
      "voice           8442  348836    9445 |  0.95  0.97\n",
      "environment      548    4407  370091 |  0.99  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.95    0.97\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 4\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 252s 227us/step - loss: 0.0925 - acc: 0.9663\n",
      "                   m       v       e |  sens   acc\n",
      "music         352457   13478     601 |  0.96  0.98\n",
      "voice           8015  352300    6408 |  0.96  0.97\n",
      "environment      485    5330  369231 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.95    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 5\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 263s 237us/step - loss: 0.0882 - acc: 0.9678\n",
      "                   m       v       e |  sens   acc\n",
      "music         352521   13508     507 |  0.96  0.98\n",
      "voice           7284  356715    2724 |  0.97  0.97\n",
      "environment      445   11883  362718 |  0.97  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.93    0.99\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseModelFilename = '20180720_allOrgs'\n",
    "modelFilePath = storageFolder\n",
    "layers = [400, 300, 200, 100, 50, 20, 10]\n",
    "\n",
    "LOG_HEADER('Alle orgs, lagen: [400, 300, 200, 100, 50, 20, 10]', True)\n",
    "\n",
    "nrEpochs = 5\n",
    "train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################\n",
      "#\n",
      "# Alle orgs, lagen: [450, 400, 350, 300, 250, 200, 150, 100, 50, 21]\n",
      "#\n",
      "####################################\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 1\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 353s 319us/step - loss: 0.1617 - acc: 0.9418\n",
      "                   m       v       e |  sens   acc\n",
      "music         348304   17826     406 |  0.95  0.97\n",
      "voice          10841  342199   13683 |  0.93  0.96\n",
      "environment     2216    4614  368216 |  0.98  0.98\n",
      "--------------------------------------\n",
      "prec            0.96    0.94    0.96\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.94\n",
      "F1 environment: 0.97\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 2\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 351s 317us/step - loss: 0.1228 - acc: 0.9569\n",
      "                   m       v       e |  sens   acc\n",
      "music         355192   10856     488 |  0.97  0.98\n",
      "voice          14876  342950    8897 |  0.94  0.96\n",
      "environment     1090    5267  368689 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.96    0.96    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 3\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 355s 320us/step - loss: 0.1152 - acc: 0.9604\n",
      "                   m       v       e |  sens   acc\n",
      "music         351573   14570     393 |  0.96  0.97\n",
      "voice          12741  348329    5653 |  0.95  0.96\n",
      "environment      932    7508  366606 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.96    0.94    0.98\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.96\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 4\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 354s 320us/step - loss: 0.1276 - acc: 0.9610\n",
      "                   m       v       e |  sens   acc\n",
      "music         349180   16926     430 |  0.95  0.98\n",
      "voice           5923  353703    7097 |  0.96  0.97\n",
      "environment      923    6225  367898 |  0.98  0.99\n",
      "--------------------------------------\n",
      "prec            0.98    0.94    0.98\n",
      "\n",
      "F1 overall: 0.97\n",
      "F1 music: 0.97\n",
      "F1 voice: 0.95\n",
      "F1 environment: 0.98\n",
      "\n",
      "\n",
      "*****************\n",
      "* Epoch nr 5\n",
      "*****************\n",
      "\n",
      "Epoch 1/1\n",
      "1108305/1108305 [==============================] - 357s 322us/step - loss: 0.1072 - acc: 0.9645\n",
      "                   m       v       e |  sens   acc\n",
      "music         343245   23042     249 |  0.94  0.97\n",
      "voice           8832  352862    5029 |  0.96  0.96\n",
      "environment     1165    8473  365408 |  0.97  0.99\n",
      "--------------------------------------\n",
      "prec            0.97    0.92    0.99\n",
      "\n",
      "F1 overall: 0.96\n",
      "F1 music: 0.95\n",
      "F1 voice: 0.94\n",
      "F1 environment: 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseModelFilename = '20180720_allOrgs'\n",
    "modelFilePath = storageFolder\n",
    "layers = [450, 400, 350, 300, 250, 200, 150, 100, 50, 21]\n",
    "\n",
    "LOG_HEADER('Alle orgs, lagen: [450, 400, 350, 300, 250, 200, 150, 100, 50, 21]', True)\n",
    "\n",
    "nrEpochs = 5\n",
    "train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv testen"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def createAndStoreTestData(wavFileParts, fileData, micNr, filename, keyName):\n",
    "    allSpectros = np.array([])\n",
    "    allClasses = np.array([])\n",
    "\n",
    "    for wfPt in wavFileParts: #type: WavFilePart\n",
    "        if not 'Gunshot' in wfPt.getSoundType():\n",
    "            filename = datasetDir + '/{:d}_{:d}_mono{:d}.wav'.format(fileDate, wfPt.fileNr, micNr)\n",
    "            fs, signal = wv.read(filename)\n",
    "\n",
    "            classNr = classes.index(wfPt.getSoundType().lower())\n",
    "            for soundChunk in wfPt.getSoundChunks(micNr):\n",
    "                startFrame = int(soundChunk[0] * fs)\n",
    "                endFrame = int(soundChunk[1] * fs)\n",
    "\n",
    "                sigChunk = signal[startFrame: endFrame]\n",
    "                freq_array, segment_times, spectrogram = sig.spectrogram(x=sigChunk, fs=fs, nfft=NFFT, noverlap=0)\n",
    "                if len(allSpectros) == 0:\n",
    "                    allSpectros = spectrogram.T\n",
    "                else:\n",
    "                    allSpectros = np.append(allSpectros, spectrogram.T, axis=0)\n",
    "                allClasses = np.append(allClasses, classNr * np.ones(len(segment_times)))\n",
    "                \n",
    "    storeTestData(allSpectros, allClasses, filename, keyName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "251px",
    "left": "448.415px",
    "right": "20px",
    "top": "98.9773px",
    "width": "579px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
