{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zelfde experiment; eerst downsamplen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wv\n",
    "import scipy.signal as sig\n",
    "import wave\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "from util import util\n",
    "from util import WavFileParts\n",
    "from util.logUtil import LOG, LOG_HEADER\n",
    "from util.confusionMatrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Centrale parameters: targetFreq, windowLength / NFFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetFreq = 8000\n",
    "windowLength = 0.032 \n",
    "NFFT = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### globale settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['music', 'voice', 'environment']\n",
    "\n",
    "macDir = '/Volumes/SAA_DATA/datasets/'\n",
    "winDir = 'E:/SAA_DATA/'\n",
    "osDir = winDir\n",
    "recordingDir = osDir + '/localizationRecordings'\n",
    "\n",
    "if osDir == winDir:\n",
    "    storageFolder = 'E:/SAA_DATA/storedData/'\n",
    "else:\n",
    "    storageFolder = '/Users/etto/Desktop/storedData/'\n",
    "\n",
    "baseSrcDir = osDir + 'localizationFiles/20171025AllExtractionsMic4'\n",
    "orgWavDirs1 = ['G428_0.0_1.4',\n",
    "              'G527_0.5_1.4',\n",
    "              'Studio_2.0_4.2'\n",
    "              ]\n",
    "\n",
    "orgWavDirs2 = ['G428_2.1_2.4',\n",
    "              'G527_1.2_5.8',\n",
    "              'Studio_3.0_2.0'\n",
    "              ]\n",
    "\n",
    "orgsG428 = ['G428_0.0_1.4','G428_2.1_2.4']\n",
    "orgsG527 = ['G527_0.5_1.4','G527_1.2_5.8']\n",
    "orgsStudio = ['Studio_2.0_4.2','Studio_3.0_2.0']\n",
    "\n",
    "chunksBaseDir = 'chunks'\n",
    "rooms = ['Studio', 'G428', 'G527']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### utility functies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSoundChunksDynamic(moduleString):\n",
    "    chunks = importlib.import_module(moduleString).soundChunks\n",
    "    wfPts = []\n",
    "    for jsonString in chunks:\n",
    "        wfPts.append(WavFileParts.WavFilePartFromJson(jsonString))\n",
    "    return wfPts\n",
    "\n",
    "def timeFunction(func):\n",
    "    \"\"\"\n",
    "    Aanroep: bijv. fpc = timeFunction(lambda: getFilesPerCategory(srcDir))\n",
    "    \"\"\"\n",
    "    startTime = datetime.now()\n",
    "    print('Start: ' + startTime.strftime('%H:%M:%S') + '\\n=================')\n",
    "\n",
    "    res = func()\n",
    "    \n",
    "    endTime = datetime.now()\n",
    "    print('\\n=================\\nEnd: ' + endTime.strftime('%H:%M:%S'))\n",
    "    print('Time taken: '),\n",
    "    print(endTime - startTime)\n",
    "    print()\n",
    "    \n",
    "    return res\n",
    "    \n",
    "def storeTestData(allSpectros, allClasses, storageName, NFFT, keyName):\n",
    "    filename = storageFolder + storageName + '_NFFT{:d}.hd5'.format(NFFT)\n",
    "    df = pd.DataFrame(allSpectros)\n",
    "    df.to_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "\n",
    "    df = pd.DataFrame(allClasses)\n",
    "    df.to_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "\n",
    "def retrieveTestData(storageName, NFFT, keyName):\n",
    "    filename = storageFolder + storageName + '_NFFT{:d}.hd5'.format(NFFT)\n",
    "    specDf = pd.read_hdf(path_or_buf=filename, key='spectros_' + keyName)\n",
    "    classesDf = pd.read_hdf(path_or_buf=filename, key='classes_' + keyName)\n",
    "    return specDf.values, classesDf.values\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv trainen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie alle files (volledig pad) uit de srcDir\n",
    "# srcDir is een van de orgWavDirs, bijvoorbeeld\n",
    "#    localizationFiles/20171025AllExtractionsMic4/G428_0.0_1.4\n",
    "def getFilesPerCategory(srcDir):\n",
    "    filesPerCategory = {}\n",
    "    for catDirLong in glob.glob(srcDir + '/*'):\n",
    "        catDir = catDirLong.replace('\\\\', '/')\n",
    "        catDir = catDir.replace(srcDir + '/', '')\n",
    "\n",
    "        filesPerCategory[catDir] = []\n",
    "        for filename in glob.glob(catDirLong + '/*'):\n",
    "            filename = filename.replace('\\\\','/')\n",
    "            filesPerCategory[catDir].append(filename)\n",
    "    return filesPerCategory\n",
    "\n",
    "def getFilesPerCatFromMultipleDirs(srcDirs, srcDirsBase=''):\n",
    "    filesPerCat = {}\n",
    "    for dirName in srcDirs:\n",
    "        srcDir = srcDirsBase + '/' + dirName\n",
    "        fpcNw = getFilesPerCategory(srcDir)\n",
    "        if not filesPerCat:\n",
    "            filesPerCat = fpcNw\n",
    "        else:\n",
    "            for key in filesPerCat:\n",
    "                filesPerCat[key] += fpcNw[key]\n",
    "    return filesPerCat\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dowsampling functions\n",
    "def getDownsampledSignal(signal, fsOrg, fsTarget):\n",
    "    lpSignal = applyLowpassFilter(signal, int(fsTarget / 2), fsOrg)\n",
    "    print('lowpassed')\n",
    "    numSamples = int(fsTarget * 1.0 * len(lpSignal) / fsOrg)\n",
    "    print('numsamples: {}'.format(numSamples))\n",
    "    dsSignal = np.array(sig.resample(lpSignal, numSamples))\n",
    "    print('resampled')\n",
    "    return dsSignal\n",
    "\n",
    "def applyLowpassFilter(signal, hiFrq, fs):\n",
    "    b, a = sig.butter(2, 1.0 * hiFrq / fs)\n",
    "    return sig.lfilter(b, a, signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maakt een dictionary aan; per categorie de spectrogrammen\n",
    "def getSpectrosFromFilesPerCategory(filesPerCategory, fsTarget, NFFT):\n",
    "    spectros = {}\n",
    "    for clz in classes:\n",
    "        spectros[clz] = []\n",
    "        for filename in filesPerCategory[clz]:\n",
    "            fsOrg, signal = wv.read(filename)\n",
    "            print('reading ' + filename)\n",
    "            signal = getDownsampledSignal(signal, fsOrg, fsTarget)\n",
    "            print('downsampled')\n",
    "            freq_array, segment_times, spectrogram = sig.spectrogram(x=signal, fs=fsTarget, nperseg=NFFT, noverlap=0)\n",
    "            print('spec')\n",
    "            spectros[clz].append(spectrogram.T)\n",
    "    return spectros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getClassLengths(spectrosPerCat):\n",
    "    clzLengths = {}\n",
    "    for clz in classes:\n",
    "        clzLengths[clz] = sum([np.shape(lst)[0] for lst in spectrosPerCat[clz]])\n",
    "    return clzLengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verwacht invoer van getSpectrosFromFilesPerCategory\n",
    "# levert traindata op (X_train en Y_train)\n",
    "def createTrainDataFromSpectros(spectrosPerCat, clzLengths):\n",
    "    X_train = np.concatenate(spectrosPerCat[classes[0]], axis=0)\n",
    "    for i in range(1, len(classes)):\n",
    "        nwSpectros = np.concatenate(spectrosPerCat[classes[i]], axis=0)\n",
    "        X_train = np.concatenate((X_train,nwSpectros), axis=0)\n",
    "    \n",
    "    # one-hot encoding voor Y_train\n",
    "    nrFiles = clzLengths[classes[0]]\n",
    "    Y_train = np.array((np.ones(nrFiles),np.zeros(nrFiles), np.zeros(nrFiles))).T\n",
    "\n",
    "    nrFiles = clzLengths[classes[1]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.ones(nrFiles), np.zeros(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "\n",
    "    nrFiles = clzLengths[classes[2]]\n",
    "    Y_train_nw = np.array((np.zeros(nrFiles), np.zeros(nrFiles), np.ones(nrFiles))).T\n",
    "    Y_train = np.concatenate((Y_train, Y_train_nw),axis=0)\n",
    "    \n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(layersizes, NFFT):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layersizes[0], input_dim=(int(NFFT/2+1)), activation='relu'))\n",
    "    for lsize in layersizes[1:]:\n",
    "        model.add(Dense(lsize, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs):\n",
    "    modelFilename = modelFilePath + baseModelFilename\n",
    "    for lsize in layers:\n",
    "        modelFilename = '{}_{}'.format(modelFilename, lsize)\n",
    "    modelFilename += 'ep{}'.format(nrEpochs)\n",
    "    modelFilename += '.hd5'\n",
    "    return modelFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModelName(baseModelFilename, layers, nrEpochs):\n",
    "    modelFilename = baseModelFilename\n",
    "    for lsize in layers:\n",
    "        modelFilename = '{}_{}'.format(modelFilename, lsize)\n",
    "    modelFilename += 'ep{}'.format(nrEpochs)\n",
    "    return modelFilename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, Y_train, layers, nrEpochs, modelFilePath, baseModelFilename, NFFT, batch_size=None):\n",
    "    soundModel = create_model(layers, NFFT)\n",
    "    history = timeFunction(lambda: soundModel.fit(X_train,Y_train, epochs=nrEpochs, shuffle=True, verbose=1, batch_size=batch_size))\n",
    "    soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(X_train, Y_train, realTrainClasses, layers, nrEpochs, modelFilePath, baseModelFilename, NFFT, batch_size=None):\n",
    "    soundModel = create_model(layers, NFFT)\n",
    "    history = timeFunction(lambda: soundModel.fit(X_train,Y_train, epochs=nrEpochs, shuffle=True, verbose=1, batch_size=batch_size))\n",
    "    soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.show()\n",
    "    evaluate_model(X_train, realTrainClasses,layers, nrEpochs, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(X_test, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename):\n",
    "    soundModel = load_model(getModelFileName(modelFilePath, baseModelFilename, layers, nrEpochs))\n",
    "\n",
    "    # predicted classes\n",
    "    predictions = soundModel.predict(X_test)\n",
    "    predClasses = predictions.argmax(axis=1)\n",
    "\n",
    "    matrix = ConfusionMatrix(classes)\n",
    "    for vals in zip(realClasses, predClasses):\n",
    "        matrix.add(int(vals[0]), int(vals[1]), 1)\n",
    "    LOG(matrix.toString(),True)\n",
    "    LOG('', True)\n",
    "    LOG(matrix.toF1String(), True)\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_per_epoch(X_train, Y_train, realClasses, layers, nrEpochs, modelFilePath, baseModelFilename, NFFT, batch_size=None):\n",
    "    soundModel = create_model(layers, NFFT)\n",
    "    for epNr in range(1, nrEpochs+1):\n",
    "        LOG('\\n*****************\\n* Epoch nr {}\\n*****************\\n'.format(epNr), True)\n",
    "        soundModel.fit(X_train,Y_train, epochs=1, shuffle=True, verbose=1, batch_size=batch_size)\n",
    "        soundModel.save(getModelFileName(modelFilePath, baseModelFilename, layers, epNr))\n",
    "        evaluate_model(X_train, realClasses, layers, epNr, modelFilePath, baseModelFilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functies tbv testen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createAndStoreTestData(wavFileParts, baseDir, fileDate, micNr, storeFilename, NFFT, keyName):\n",
    "    allSpectros = np.array([])\n",
    "    allClasses = np.array([])\n",
    "\n",
    "    for wfPt in wavFileParts: #type: WavFilePart\n",
    "        if not 'Gunshot' in wfPt.getSoundType():\n",
    "            filename = baseDir + '/{:d}_{:d}_mono{:d}.wav'.format(fileDate, wfPt.fileNr, micNr)\n",
    "            fsOrg, signal = wv.read(filename)\n",
    "            signal = getDownsampledSignal(signal, fsOrg, fsTarget)\n",
    "\n",
    "            classNr = classes.index(wfPt.getSoundType().lower())\n",
    "            for soundChunk in wfPt.getSoundChunks(micNr):\n",
    "                startFrame = int(soundChunk[0] * fsTarget)\n",
    "                endFrame = int(soundChunk[1] * fsTarget)\n",
    "\n",
    "                sigChunk = signal[startFrame: endFrame]\n",
    "                freq_array, segment_times, spectrogram = sig.spectrogram(x=sigChunk, fs=fsTarget, nperseg=NFFT, noverlap=0)\n",
    "                if len(allSpectros) == 0:\n",
    "                    allSpectros = spectrogram.T\n",
    "                else:\n",
    "                    allSpectros = np.append(allSpectros, spectrogram.T, axis=0)\n",
    "                allClasses = np.append(allClasses, classNr * np.ones(len(segment_times)))       \n",
    "    storeTestData(allSpectros, allClasses, storeFilename, NFFT, keyName)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTrainDataFromFolders(orgWavDirs, targetFrq, NFFT):\n",
    "    fpc = getFilesPerCatFromMultipleDirs(orgWavDirs, baseSrcDir)\n",
    "    spcs = getSpectrosFromFilesPerCategory(fpc, targetFrq, NFFT)\n",
    "    clzLengths = getClassLengths(spcs)\n",
    "    X_train, Y_train = createTrainDataFromSpectros(spcs, clzLengths)\n",
    "    # real train classes\n",
    "    realTrainClasses = np.concatenate((np.zeros(clzLengths[classes[0]]), \n",
    "                                  np.ones(clzLengths[classes[1]]), \n",
    "                                  2*np.ones(clzLengths[classes[2]])))\n",
    "    return X_train, Y_train, realTrainClasses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModellen(modelFilePath, layerss, NFFT, micNr, testFileNames, showOverall=True):\n",
    "\n",
    "    # test data\n",
    "    keyname = 'mic{}'.format(micNr)\n",
    "\n",
    "    for layers in layerss:\n",
    "        for nrEpochs in nrsEpochs:\n",
    "            overallMatrix = ConfusionMatrix(classes)\n",
    "            for testFileName in testFileNames:\n",
    "                testSpecs, testClasses = retrieveTestData(testFileName, NFFT, keyname)\n",
    "\n",
    "                LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                           + '\\n# ' + keyname\n",
    "                           + '\\n# ' + testFileName,\n",
    "                           True)\n",
    "                matrix = evaluate_model(testSpecs, testClasses, layers, nrEpochs, modelFilePath, baseModelFilename)\n",
    "                overallMatrix.addMatrix(matrix.normalizedCopy())\n",
    "            \n",
    "            if showOverall:\n",
    "                overallMatrix = overallMatrix.normalizedCopy()\n",
    "                LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                           + '\\n# ' + keyname\n",
    "                           + '\\n# ' + 'testData_Overall',\n",
    "                           True)\n",
    "                LOG(overallMatrix.toString(),True)\n",
    "                LOG('', True)\n",
    "                LOG(overallMatrix.toF1String(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModel(modelFilePath, layers, micNr, testFileNames, nrEpochs, showOverall=True):\n",
    "\n",
    "    # test data\n",
    "    keyname = 'mic{}'.format(micNr)\n",
    "\n",
    "    overallMatrix = ConfusionMatrix(classes)\n",
    "    for testFileName in testFileNames:\n",
    "        testSpecs, testClasses = retrieveTestData(testFileName, keyname)\n",
    "\n",
    "        LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                   + '\\n# ' + keyname\n",
    "                   + '\\n# ' + testFileName,\n",
    "                   True)\n",
    "        matrix = evaluate_model(testSpecs, testClasses, layers, nrEpochs, modelFilePath, baseModelFilename)\n",
    "        overallMatrix.addMatrix(matrix.normalizedCopy())\n",
    "\n",
    "    if showOverall:\n",
    "        overallMatrix = overallMatrix.normalizedCopy()\n",
    "        LOG_HEADER(getModelName(baseModelFilename, layers, nrEpochs) \n",
    "                   + '\\n# ' + keyname\n",
    "                   + '\\n# ' + 'testData_Overall',\n",
    "                   True)\n",
    "        LOG(overallMatrix.toString(),True)\n",
    "        LOG('', True)\n",
    "        LOG(overallMatrix.toF1String(), True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### trainen van model obv: alles G428, G527 en Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train voor alle lagen\n",
    "baseModelFilename = '20190112_fs_{}_NFFT{}'.format(targetFreq, NFFT)\n",
    "modelFilePath = storageFolder\n",
    "logPrefix = 'Alle orgs'\n",
    "orgWavDirs = orgsG428 + orgsG527 + orgsStudio\n",
    "orgWavDirs = ['G428_2.1_2.4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, realTrainClasses = getTrainDataFromFolders(orgWavDirs, targetFreq, NFFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Maak test data\n",
    "LOG_HEADER('maak spectra voor testdata G428, NFFT={}'.format(NFFT), True)\n",
    "wvPts = readSoundChunksDynamic('chunks.G428.soundChunks')\n",
    "baseDir = recordingDir + '/20170221'\n",
    "fileDate = 170221\n",
    "filename = 'testData_G428'\n",
    "for micNr in [1,2,3,4]:\n",
    "    keyname = 'mic{}'.format(micNr)\n",
    "    createAndStoreTestData(wvPts, baseDir, fileDate, micNr, filename, NFFT, keyname)\n",
    "\n",
    "LOG('Klaar: spectra voor testdata G428', True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Maak test data\n",
    "LOG_HEADER('maak spectra voor testdata G527, NFFT={}'.format(NFFT), True)\n",
    "wvPts = readSoundChunksDynamic('chunks.G527.soundChunks')\n",
    "baseDir = recordingDir + '/20170221'\n",
    "fileDate = 170221\n",
    "filename = 'testData_G527'\n",
    "for micNr in [1,2,3,4]:\n",
    "    keyname = 'mic{}'.format(micNr)\n",
    "    createAndStoreTestData(wvPts, baseDir, fileDate, micNr, filename, NFFT, keyname)\n",
    "\n",
    "LOG('Klaar: spectra voor testdata G527', True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "LOG_HEADER('maak spectra voor testdata Studio, NFFT={}'.format(NFFT), True)\n",
    "wvPts = readSoundChunksDynamic('chunks.Studio.soundChunks')\n",
    "baseDir = recordingDir + '/20171011'\n",
    "fileDate = 170816\n",
    "filename = 'testData_Studio'\n",
    "for micNr in [1,2,3,4]:\n",
    "    keyname = 'mic{}'.format(micNr)\n",
    "    createAndStoreTestData(wvPts, baseDir, fileDate, micNr, filename, NFFT, keyname)\n",
    "\n",
    "LOG('Klaar: spectra voor testdata Studio', True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "layersList = [[100, 20], [400, 250, 100, 20], [400, 300, 200, 100, 50, 20, 10], \n",
    "              [450, 400, 350, 300, 250, 200, 150, 100, 50, 21]]\n",
    "nrEpochs = 5\n",
    "nrsEpochs = range(1, nrEpochs + 1)\n",
    "#nrsEpochs = [nrEpochs]\n",
    "bSize = 128"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for layers in layersList:\n",
    "    LOG_HEADER(logPrefix + ', lagen: {}'.format(str(layers)), True)\n",
    "    train_and_evaluate_per_epoch(X_train, Y_train, realTrainClasses, \n",
    "                                 layers, nrEpochs, modelFilePath, baseModelFilename, NFFT,\n",
    "                                batch_size=bSize)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Test alle modellen\n",
    "fileName='plots/20190103_NFFT{}.txt'.format(NFFT)\n",
    "with open(fileName, 'w') as f:\n",
    "    with redirect_stdout(f):       \n",
    "        testModellen(modelFilePath=storageFolder, \n",
    "                     layerss=layersList, \n",
    "                     NFFT=NFFT,\n",
    "                     micNr=4, \n",
    "                     testFileNames=['testData_G428', 'testData_G527', 'testData_Studio'], \n",
    "                     showOverall=True)                "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from parseExperimentResults import parseRedoExperiment"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "experimentId='20190103_NFFT{}'.format(NFFT)\n",
    "filePattern='20190103_NFFT{}'.format(NFFT)\n",
    "parseRedoExperiment(experimentId, filePattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "251px",
    "left": "448.415px",
    "right": "20px",
    "top": "98.9773px",
    "width": "579px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
