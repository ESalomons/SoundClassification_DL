{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import glob\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wv\n",
    "import scipy.signal as sig\n",
    "import wave\n",
    "\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "\n",
    "from util import util\n",
    "from util import WavFileParts\n",
    "from util.confusionMatrix import ConfusionMatrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['music', 'voice', 'environment']\n",
    "\n",
    "macDir = '/Volumes/SAA_DATA/datasets/'\n",
    "winDir = 'E:/SAA_DATA/'\n",
    "osDir = winDir\n",
    "\n",
    "baseTargetDir = '/Users/etto/Desktop/pData'\n",
    "baseTargetDir = 'E:/SAA_DATA/targetDir'\n",
    "\n",
    "baseSrcDir = osDir + 'localizationFiles/20171025AllExtractionsMic4'\n",
    "orgWavDirs1 = ['G428_0.0_1.4',\n",
    "              'G527_0.5_1.4',\n",
    "              'Studio_2.0_4.2'\n",
    "              ]\n",
    "\n",
    "orgWavDirs2 = ['G428_2.1_2.4',\n",
    "              'G527_1.2_5.8',\n",
    "              'Studio_3.0_2.0'\n",
    "              ]\n",
    "\n",
    "NFFT = 1024\n",
    "\n",
    "storageFolder = '../storedData/'\n",
    "chunksBaseDir = 'chunks'\n",
    "rooms = ['Studio', 'G428', 'G527']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readSoundChunksDynamic(moduleString):\n",
    "    chunks = importlib.import_module(moduleString).soundChunks\n",
    "    wfPts = []\n",
    "    for jsonString in chunks:\n",
    "        wfPts.append(WavFileParts.WavFilePartFromJson(jsonString))\n",
    "    return wfPts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evalueer op wavFileParts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "wfPts = readSoundChunksDynamic(chunksBaseDir + '.' + 'Studio' + '.soundChunks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetDir = osDir + 'localizationRecordings/20171011'\n",
    "fileDate = 170816\n",
    "micNr = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creeer spectros en sla ze op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 12:44:37\n",
      "=================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Etto\\Anaconda2\\envs\\py36DL\\lib\\site-packages\\scipy\\io\\wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=================\n",
      "End: 12:46:05\n",
      "Time taken: \n",
      "0:01:28.084052\n",
      "Ready\n"
     ]
    }
   ],
   "source": [
    "allSpectros = np.array([])\n",
    "allClasses = np.array([])\n",
    "\n",
    "startTime = datetime.now()\n",
    "print('Start: ' + startTime.strftime('%H:%M:%S') + '\\n=================')\n",
    "\n",
    "for wfPt in wfPts: #type: WavFilePart\n",
    "    if not 'Gunshot' in wfPt.getSoundType():\n",
    "        filename = datasetDir + '/{:d}_{:d}_mono{:d}.wav'.format(fileDate, wfPt.fileNr, micNr)\n",
    "        fs, signal = wv.read(filename)\n",
    "        \n",
    "        classNr = classes.index(wfPt.getSoundType().lower())\n",
    "        for soundChunk in wfPt.getSoundChunks(micNr):\n",
    "            startFrame = int(soundChunk[0] * fs)\n",
    "            endFrame = int(soundChunk[1] * fs)\n",
    "\n",
    "            sigChunk = signal[startFrame: endFrame]\n",
    "            freq_array, segment_times, spectrogram = sig.spectrogram(x=sigChunk, fs=fs, nfft=NFFT, noverlap=0)\n",
    "            if len(allSpectros) == 0:\n",
    "                allSpectros = spectrogram.T\n",
    "            else:\n",
    "                allSpectros = np.append(allSpectros, spectrogram.T, axis=0)\n",
    "            allClasses = np.append(allClasses, classNr * np.ones(len(segment_times)))\n",
    "\n",
    "endTime = datetime.now()\n",
    "print('\\n=================\\nEnd: ' + endTime.strftime('%H:%M:%S'))\n",
    "print('Time taken: '),\n",
    "print(endTime - startTime)\n",
    "\n",
    "\n",
    "filename = storageFolder + '20180717.hd5'\n",
    "df = pd.DataFrame(allSpectros)\n",
    "df.to_hdf(path_or_buf=filename, key='spectrosStudio')\n",
    "\n",
    "df = pd.DataFrame(allClasses)\n",
    "df.to_hdf(path_or_buf=filename, key='classesStudio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143836, 513)\n",
      "(143836, 1)\n"
     ]
    }
   ],
   "source": [
    "# Lees spectros weer in\n",
    "filename = storageFolder + '20180717.hd5'\n",
    "specDf = pd.read_hdf(path_or_buf=filename, key='spectrosStudio')\n",
    "classesDf = pd.read_hdf(path_or_buf=filename, key='classesStudio')\n",
    "print(np.shape(specDf))\n",
    "print(np.shape(classesDf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   m       v       e |  sens   acc\n",
      "music          37600   22090    3905 |  0.59  0.82\n",
      "voice              6   35926    1972 |  0.95  0.82\n",
      "environment       11    1552   40774 |  0.96  0.95\n",
      "--------------------------------------\n",
      "prec            1.00    0.60    0.87\n",
      "\n",
      "F1 overall: 0.80\n",
      "F1 music: 0.74\n",
      "F1 voice: 0.74\n",
      "F1 environment: 0.92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soundModel = load_model(storageFolder + 'prf20180714.hd5')\n",
    "# predicted classes\n",
    "predictions = soundModel.predict(specDf.values)\n",
    "predClasses = predictions.argmax(axis=1)\n",
    "\n",
    "matrix = ConfusionMatrix(classes)\n",
    "for vals in zip(classesDf.values, predClasses):\n",
    "    matrix.add(int(vals[0]), int(vals[1]), 1)\n",
    "print(matrix.toString())\n",
    "print()\n",
    "print(matrix.toF1String())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.],\n",
       "       [ 2.],\n",
       "       [ 2.],\n",
       "       ..., \n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classesDf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(zip(classesDf.values, predClasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.]), 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(vals[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
